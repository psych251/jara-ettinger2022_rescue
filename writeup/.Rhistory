image_path_by_shape <- 'choice_by_shape_and_property_comparison.jpeg'
#Print out the figures.
knitr::include_graphics(image_path_by_shape)
suppressMessages(library(metafor))
#Import meta-analysis data.
meta_analysis_file <- 'meta_analysis_data.csv'
meta_analysis_data <- read.csv(file.path(getwd(), '..', 'data', meta_analysis_file))
#Print out the data.
knitr::kable(meta_analysis_data,
table.attr = "class=\"striped\"",
format = "html")
#Run meta-analysis model for Abdelrahim (2022) and Chen (2023)
meta_analysis_model_random_effects <- rma(yi=random_effects_model_estimate, sei = random_effects_model_SE, slab=Study, data=meta_analysis_data)
summary(meta_analysis_model_random_effects)
#Run meta-analysis model for Jara-Ettinger et al. (2022) and Chen (2023)
meta_analysis_model_logistic_mixed_effects <- rma(yi=logistic_mixed_effects_model_estimate, sei = logistic_mixed_effects_model_SE, slab=Study, data=meta_analysis_data)
summary(meta_analysis_model_logistic_mixed_effects)
#Filter out study without this model.
meta_analysis_data_random_effects <- meta_analysis_data |>
filter(Study != "Jara-Ettinger et al. (2022)")
# Plot mini meta-analysis results.
ggplot(meta_analysis_data_random_effects, aes(x = Study, y = random_effects_model_estimate, size = N)) +
geom_point(data = meta_analysis_data_random_effects) +
coord_flip() +
ylim(-2, 2) +
scale_size_area() +
geom_hline(yintercept = 0, color = "black") +
theme_linedraw() +
theme(legend.position = "none") +
labs(y = "Main effect size on original scale", x = "")
#Filter out study without this model.
meta_analysis_data_logistic_mixed_effects <- meta_analysis_data |>
filter(Study != "Abdelrahim (2022)")
# Plot mini meta-analysis results.
ggplot(meta_analysis_data_logistic_mixed_effects, aes(x = Study, y = logistic_mixed_effects_model_estimate, size = N)) +
geom_point(data = meta_analysis_data_logistic_mixed_effects) +
coord_flip() +
ylim(-2, 2) +
scale_size_area() +
geom_hline(yintercept = 0, color = "black") +
theme_linedraw() +
theme(legend.position = "none") +
labs(y = "Main effect size on original scale", x = "")
forest(meta_analysis_model_random_effects)
forest(meta_analysis_model_logistic_mixed_effects)
funnel(meta_analysis_model_random_effects)
funnel(meta_analysis_model_logistic_mixed_effects)
#Load relevant libraries and functions.
suppressMessages(library(tidyverse))
suppressMessages(library(dplyr))
suppressMessages(library(ggplot2))
#Get all data file names from the data_raw folder.
folder_path <- file.path(getwd(), '..', 'data_raw')
#Get all file names in the folder, ignoring sub-directories.
file_names <- list.files(path = folder_path, full.names = FALSE, recursive = FALSE)
#Filter to include only files (exclude directories).
file_names <- file_names[!file.info(file.path(folder_path, file_names))$isdir]
#Check if there are any files in the list
if(length(file_names) == 0) {
print("No files found in the specified folder.")
} else {
#Create an empty dataframe to store all of the data
full_raw_data <- data.frame()
#Loop through each of the files
for(file in file_names) {
#Construct the full path to the file
file_path <- file.path(folder_path, file)
#Check if the file exists
if(file.exists(file_path)) {
#Read the data from the file
temp_data <- read.csv(file_path)
#Append the data to the full_raw_data dataframe
full_raw_data <- rbind(full_raw_data, temp_data)
} else {
print(paste("File not found:", file_path))
}
}
}
suppressMessages(library(stringr))
#If true, then all images loaded successfully for all subjects.
print(paste("Images loaded successfully for all subjects:", sum(str_detect(full_raw_data$success, 'false')) == 0))
subject_check <- full_raw_data |>
group_by(PROLIFIC_PID) |>
summarize(numRows = n())
#If a subject completed the study once, they should have 18 rows.
repeat_subjects <- subset(subject_check, numRows > 18)
cat(nrow(repeat_subjects), "subjects did the study more than once.")
#Since the data were collected in 8 batches, there are repeat subject IDs (`batchSubjectID`). Create a new column called `subjectID` and make each one unique to the combined dataset. Each subject has one 'fullscreen' trial so use that to assign a unique subject ID.
suppressMessages(library(data.table))
#Convert the dataframe to a data.table
setDT(full_raw_data)
#Create a new column 'subjectID' based on unique subject codes
full_raw_data[, subjectID := .GRP, by = PROLIFIC_PID]
#Convert data.table back to a dataframe
full_raw_data <- as.data.frame(full_raw_data)
#Select only relevant columns and rename them.
data_main_analyses <- full_raw_data |>
select(c('rt', 'trial_type', 'run_id', 'subjectID', 'condition', 'recorded_at', 'device', 'success', 'stimulus', 'response', starts_with('exemplar'), starts_with('extension'))) |>
rename(reactionTime = rt, trialType = trial_type, batchSubjectID = run_id, recordedAt = recorded_at, imageLoadSuccess = success) |> #Rename columns to match naming conventions.
filter(device != 'iPhone') |>  #Remove subjects who used phones.
select(c(-'device', -'recordedAt')) #Remove columns that aren't necessary anymore.
#Put demographic responses (currently in the 'response' column) into their own columns.
for(row_index in 1:nrow(data_main_analyses)) {
participant_response <- data_main_analyses[row_index, 'response'] #Create a variable for the response in the current row
stimulus <- data_main_analyses[row_index, 'stimulus'] #Create a variable for the stimulus in the current row
#Check that the 'response' is not an empty string.
if(nzchar(participant_response)) {
#Check if it's a survey response (has {} in the string) and update.
if(grepl("{", participant_response, fixed = TRUE)) {
#Attention check: left image.
if(grepl('extensionLeftImg_exemplar_commonalities', participant_response)) {
temp_response <- strsplit(participant_response, ':')[[1]][2] #Get only the answer
temp_response <- gsub('["}]', '', temp_response) #Trim the extra characters
data_main_analyses[row_index, 'extensionLeftImgAttnCheckResponse'] <- temp_response
}
#Attention check: center image.
else if(grepl('extensionCenterImg_exemplar_commonalities', participant_response)) {
temp_response <- strsplit(participant_response, ':')[[1]][2] #Get only the answer
temp_response <- gsub('["}]', '', temp_response) #Trim the extra characters
data_main_analyses[row_index, 'extensionCenterImgAttnCheckResponse'] <- temp_response
}
#Attention check: right image.
else if(grepl('extensionRightImg_exemplar_commonalities', participant_response)) {
temp_response <- strsplit(participant_response, ':')[[1]][2] #Get only the answer
temp_response <- gsub('["}]', '', temp_response) #Trim the extra characters
data_main_analyses[row_index, 'extensionRightImgAttnCheckResponse'] <- temp_response
}
#Participant age.
else if(grepl('Age', participant_response)) {
temp_response <- strsplit(participant_response, ':')[[1]][2] #Get only the answer
temp_response <- gsub('["}]', '', temp_response) #Trim the extra characters
data_main_analyses[row_index, 'participantAge'] <- temp_response
}
#Geographical location.
else if(grepl('CurrentUSA', participant_response)) {
temp_response <- strsplit(participant_response, ',') #List of responses for BornUSA, ChildhoodUSA, and CurrentUSA.
#Participant birth location.
if(grepl('BornUSA', temp_response[[1]][1])) {
geog_temp_response <- strsplit(temp_response[[1]][1], ':')[[1]][2] #Get only the answer for BornUSA.
geog_temp_response <- gsub('["}]', '', geog_temp_response) #Trim the extra characters
data_main_analyses[row_index, 'participantBornUSA'] <- geog_temp_response
}
#Participant childhood location.
if(grepl('ChildhoodUSA', temp_response[[1]][2])) {
geog_temp_response <- strsplit(temp_response[[1]][2], ':')[[1]][2] #Get only the answer for ChildhoodUSA.
geog_temp_response <- gsub('["}]', '', geog_temp_response) #Trim the extra characters
data_main_analyses[row_index, 'participantChildhoodUSA'] <- geog_temp_response
}
#Participant current location.
if(grepl('CurrentUSA', temp_response[[1]][3])) {
geog_temp_response <- strsplit(temp_response[[1]][3], ':')[[1]][2] #Get only the answer for CurrentUSA.
geog_temp_response <- gsub('["}]', '', geog_temp_response) #Trim the extra characters
data_main_analyses[row_index, 'participantCurrentUSA'] <- geog_temp_response
}
}
#Zipcodes.
else if(grepl('CurrentZipcode', participant_response)) {
temp_response <- strsplit(participant_response, ',') #List of responses for CurrentZipcode and ChildhoodZipcode.
#Participant current zipcode.
if(grepl('CurrentZipcode', temp_response[[1]][1])) {
zipcode_temp_response <- strsplit(temp_response[[1]][1], ':')[[1]][2] #Get only the answer for CurrentZipcode.
zipcode_temp_response <- gsub('["}]', '', zipcode_temp_response) #Trim the extra characters
data_main_analyses[row_index, 'participantCurrentZipcode'] <- zipcode_temp_response
}
#Participant childhood zipcode.
if(grepl('ChildhoodZipcode', temp_response[[1]][2])) {
zipcode_temp_response <- strsplit(temp_response[[1]][2], ':')[[1]][2] #Get only the answer for ChildhoodZipcode.
zipcode_temp_response <- gsub('["}]', '', zipcode_temp_response) #Trim the extra characters
data_main_analyses[row_index, 'participantChildhoodZipcode'] <- zipcode_temp_response
}
}
#Languages.
else if(grepl('FirstLanguage', participant_response)) {
temp_response <- strsplit(participant_response, '",') #List of responses for FirstLanguage and AllLanguages.
#Participant first language.
if(grepl('FirstLanguage', temp_response[[1]][1])) {
language_temp_response <- strsplit(temp_response[[1]][1], ':')[[1]][2] #Get only the answer for FirstLanguage.
language_temp_response <- gsub('["}]', '', language_temp_response) #Trim the extra characters
data_main_analyses[row_index, 'participantFirstLanguage'] <- language_temp_response
}
#Participant all languages spoken.
if(grepl('AllLanguages', temp_response[[1]][2])) {
language_temp_response <- strsplit(temp_response[[1]][2], ':')[[1]][2] #Get only the answer for AllLanguages.
language_temp_response <- gsub('["}]', '', language_temp_response) #Trim the extra characters
data_main_analyses[row_index, 'participantCurrentLanguages'] <- language_temp_response
}
}
}
#Check if it's a numerical response for participant's current location urbanicity rating (1-100).
else if(grepl("^[0-9]+$", participant_response) & (grepl('currently live', stimulus, fixed = TRUE))) {
data_main_analyses[row_index, 'participantCurrentUrbanicity'] <- participant_response
}
#Check if it's a numerical response for participant's childhood location urbanicity rating (1-100).
else if(grepl("^[0-9]+$", participant_response) & (grepl('grew up', stimulus, fixed = TRUE))) {
#Participant's childhood location urbanicity.
data_main_analyses[row_index, 'participantChildhoodUrbanicity'] <- participant_response
}
#Check if it's an image response (choosing the shape image).
else if(grepl("^[0-9]+$", participant_response) & (grepl('img', stimulus, fixed = TRUE))) {
data_main_analyses[row_index, 'participantExtensionChoice'] <- participant_response
}
}
#Interpret the participantExtensionChoice column to make the numerical answer choice values meaningful.
participant_image_choice <- data_main_analyses[row_index, 'participantExtensionChoice']
if(!is.na(participant_image_choice) && length(participant_image_choice) > 0) {
#Participant chose the left image.
if(participant_image_choice == "0") {
data_main_analyses[row_index, 'participantExtensionChoiceImage'] <- data_main_analyses[row_index, 'extensionLeftImg']
}
#Participant chose the center image.
else if(participant_image_choice == "1") {
data_main_analyses[row_index, 'participantExtensionChoiceImage'] <- data_main_analyses[row_index, 'extensionCenterImg']
}
#Participant chose the right image.
else if(participant_image_choice == "2") {
data_main_analyses[row_index, 'participantExtensionChoiceImage'] <- data_main_analyses[row_index, 'extensionRightImg']
}
}
}
#Combine subject rows into a single row and remove the extra columns.
data_main_analyses_tidy <- data_main_analyses |>
select(-reactionTime, -trialType, -imageLoadSuccess, -stimulus, -response, -batchSubjectID) |>
mutate(across(everything(), ~ ifelse(. == "", NA, .))) |>  #Replace empty strings with NA
group_by(subjectID) |>
summarize(across(everything(), ~ if(all(is.na(.))) {NA} else {na.omit(.)[1]}), .groups = "drop")
#Check that there are enough subjects per condition.
condition_check <- data_main_analyses_tidy |>
group_by(condition) |>
summarize(numSubjectsPerCondition = n()) #Count the number of times the condition comes up
print(paste("There are an equal number of subjects per condition:", all(condition_check$numSubjectsPerCondition == condition_check$numSubjectsPerCondition[1]))) #If true, then there are an equal number of subjects per condition.
#Check if there are null (NA) values in participantExtensionChoice.
null_values <- sum(is.na(data_main_analyses_tidy$participantExtensionChoice))
#Print the result
if (null_values > 0) {
cat("Out of", nrow(data_main_analyses_tidy), "subjects, there are", null_values, "null values in the column 'participantExtensionChoice.'.\n")
} else {
cat("Out of", nrow(data_main_analyses_tidy), "subjects, there are no null values in the column 'participantExtensionChoice.'.\n")
}
#Remove rows that don't have a response in participantExtensionChoice.
data_main_analyses_tidy <- data_main_analyses_tidy[!is.na(data_main_analyses_tidy$participantExtensionChoice), ]
#Check if the data were removed.
null_values <- sum(is.na(data_main_analyses_tidy$participantExtensionChoice))
#Print the result
if (null_values > 0) {
cat("After data cleaning, there are", null_values, "null values in the column 'participantExtensionChoice' and", nrow(data_main_analyses_tidy), "total subjects. \n")
} else {
cat("After data cleaning, there are no null values in the column 'participantExtensionChoice' and", nrow(data_main_analyses_tidy), "total subjects. \n")
}
#Go through each subject.
for(row_index in 1:nrow(data_main_analyses_tidy)) {
#Get the exemplar the participant saw.
participant_exemplar <- unlist(strsplit(as.character(data_main_analyses_tidy[row_index, 'exemplarImg']), '_'))
#Get the extension the participant chose.
participant_extension_choice <- unlist(strsplit(as.character(data_main_analyses_tidy[row_index, 'participantExtensionChoiceImage']), '_'))
#Get the shape of the exemplar object and put into a new column called exemplarShape.
exemplar_shape <- participant_exemplar[3]
data_main_analyses_tidy[row_index, 'exemplarShape'] <- exemplar_shape
#Get the overlapping property.
overlap <- intersect(participant_exemplar, participant_extension_choice)
#Put the overlapping property into a new column.
data_main_analyses_tidy[row_index, 'participantOverlapAnswer'] <- overlap
#Interpret the overlapping answer
if(overlap == 'red' | overlap == 'blue' | overlap == 'yellow') {
data_main_analyses_tidy[row_index, 'participantOverlapProperty'] <- 'color'
}
else if(overlap == 'crepe' | overlap == 'foam' | overlap == 'yarn') {
data_main_analyses_tidy[row_index, 'participantOverlapProperty'] <- 'material'
}
else if(overlap == 'arch' | overlap == 'lamp' | overlap == 'snowman') {
data_main_analyses_tidy[row_index, 'participantOverlapProperty'] <- 'shape'
}
}
data_main_analyses_tidy <- data_main_analyses_tidy |>
mutate(participantLocation = 'US', experiment = 'USA_Adults', ageGroup = 'Adults', exclude = 0) |>
select(subjectID, condition, experiment, ageGroup, participantLocation, exemplarName, exemplarImg, exemplarShape, participantOverlapAnswer, participantOverlapProperty, participantExtensionChoice, participantExtensionChoiceImage, extensionLeftImg, extensionCenterImg, extensionRightImg, extensionLeftImgAttnCheckResponse, extensionCenterImgAttnCheckResponse, extensionRightImgAttnCheckResponse, participantAge, participantBornUSA, participantChildhoodUSA, participantCurrentUSA, participantCurrentZipcode, participantChildhoodZipcode, participantFirstLanguage, participantCurrentLanguages, participantCurrentUrbanicity, participantChildhoodUrbanicity, exclude)
#Load libraries
suppressMessages(library(tidyverse))
suppressMessages(library(boot))
suppressMessages(library(lme4))
#Load data
original_data_file <- "Original_ShapeBias_Data.csv"
original_data_path <- file.path(getwd(), '..', 'data', original_data_file)
original_data <- read.csv(original_data_path)
table(original_data$Experiment) #Contains data from all 7 experiments.
#Number of participants
original_data |> group_by(AgeGroup,Location) %>% summarize(subjects=n(), .groups = 'drop')
#Stats by experiment
summary_data_original <- original_data |>
group_by(Experiment) |>
summarize(subjects=n(),
average=mean(Age,na.rm=TRUE),
minage=min(Age,na.rm=TRUE),
maxage=max(Age,na.rm=TRUE),
stdev=sd(Age,na.rm=TRUE),
ShapeNo=sum(Choice=="Shape"),
MatNo=sum(Choice=="Material"),
ColorNo=sum(Choice=="Color"),
DistNo=sum(Choice=="Distractor"),
ShapePerc=ShapeNo/subjects,
MatPerc=MatNo/subjects,
ColorPerc=ColorNo/subjects,
DistPerc=DistNo/subjects)
summary_data_original$ExpNo <- c(6,7,2,4,3,1,5)
summary_data_original <- arrange(summary_data_original,ExpNo)
#Results
summary_data_original |>
dplyr::select(ExpNo, Experiment, subjects, ShapeNo, MatNo, ColorNo, DistNo, ShapePerc, MatPerc, ColorPerc, DistPerc)
#Reproduce the binomial test for Experiment 5: US_Turk_Adults.
CurrExp <- summary_data_original |>
filter(ExpNo==5)
binom.test(CurrExp$ShapeNo, CurrExp$subjects, p=1/3)
#This model predicts the participant's preference for the shape-match object.
CurrExp <- original_data |>
filter(Experiment %in% c("Tsi_Adults_Objects","Tsi_Adults_wDistractor", "US_Turk_Adults","Tsi_Child_Objects","US_Children")) |>
filter(Choice!="Distractor")
CurrExp$Offset <- logit(1/3)
m <- glmer(Choice=="Shape" ~ offset(Offset) + Location * AgeGroup + (1 + Location + AgeGroup| Example) + (1 | Experiment),CurrExp,family="binomial")
summary(m)
#Actual model: main effects of `Location` and `AgeGroup` tested without their interaction.
m0 <- glmer(Choice=="Shape" ~ offset(Offset) + Location + AgeGroup + (1 + Location + AgeGroup | Example) + (1 | Experiment),CurrExp,family="binomial")
anova(m,m0)
summary(m0)
#Summary statistics
summary_data <- data_main_analyses_tidy |>
summarize(subjects=n(),
average=mean(as.numeric(participantAge), na.rm=TRUE),
minage=min(as.numeric(participantAge), na.rm=TRUE),
maxage=max(as.numeric(participantAge), na.rm=TRUE),
stdev=sd(as.numeric(participantAge), na.rm=TRUE),
shapeNum=sum(participantOverlapProperty=="shape"),
materialNum=sum(participantOverlapProperty=="material"),
colorNum=sum(participantOverlapProperty=="color"),
shapePercent=shapeNum/subjects,
matPercent=materialNum/subjects,
colorPercent=colorNum/subjects,
.groups = 'drop') |>
ungroup()
#Binomial test
binomial_result <- binom.test(summary_data$shapeNum, summary_data$subjects, p=1/3)
binomial_result
#Store values of 95% confidence intervals.
conf_int <- binomial_result$conf.int
#Create dataframe for figure.
figure_statistics <- data_main_analyses_tidy |>
group_by(participantOverlapProperty, participantLocation) |>
summarize(n = n(), proportion = n / nrow(data_main_analyses_tidy), .groups = 'drop') |>
ungroup()
#Plot the data for the first figure and save as a file.
ggplot(figure_statistics, aes(y = proportion, x = participantLocation, fill = participantOverlapProperty)) +
geom_bar(position = "stack", stat = 'identity', width = .7) +
geom_errorbar(aes(ymin = conf_int[1], ymax = conf_int[2]), width = .2) +
theme_minimal() +
scale_fill_manual(values = c("#B4DCB9", "#7F92B8", "#6C6969")) +
scale_x_discrete('Experiment 5: USA Adults') +
scale_y_continuous('Percentage of responses', labels = scales::percent) +
facet_wrap(~participantLocation) +
geom_hline(yintercept = (1/3), linetype = 'dotted', color = 'black') +
labs(fill = "Choice") +
theme(legend.title = element_text(size = 12, face = "bold"))
img_path <- file.path(getwd(), '..', 'figures', 'choice_by_property_rescue.png')
ggsave(img_path, device = 'png', dpi=300)
#Calculate the percentages of each choice by property and output into a dataframe.
count_df <- data_main_analyses_tidy |>
group_by(exemplarShape, participantOverlapProperty, experiment) |>
summarize(count = n(), .groups = 'drop') |>
ungroup()
#Pivot the dataframe.
figure_statistics_by_shape_property <- pivot_wider(count_df, id_cols = exemplarShape, names_from = participantOverlapProperty, values_from = count)
figure_statistics_by_shape_property[is.na(figure_statistics_by_shape_property)] <- 0 #Make NULL values 0
#Calculate the proportion of responses for each property.
figure_statistics_by_shape_property$totalCount <- rowSums(figure_statistics_by_shape_property[, -1]) #Calculate the total responses per property
columns_to_calculate <- c("shape", "material", "color")  #All possible properties
existing_columns <- intersect(columns_to_calculate, names(figure_statistics_by_shape_property)) #Find columns that actually exist
figure_statistics_by_shape_property <- figure_statistics_by_shape_property |>
mutate(across(all_of(existing_columns), ~ .x / totalCount, .names = "{.col}Proportion")) #Takes into account if properties don't exist.
#Pivot the data.
figure_statistics_by_shape_property_long <- figure_statistics_by_shape_property |>
pivot_longer(
cols = any_of(c("shapeProportion", "materialProportion", "colorProportion")),
names_to = "exemplarProperty",
values_to = "proportion"
)
#Clean up the property value names.
figure_statistics_by_shape_property_long$exemplarProperty <- sub("Proportion", "", figure_statistics_by_shape_property_long$exemplarProperty)
#Binomial tests.
binomial_result_arch <- binom.test(figure_statistics_by_shape_property$shape[figure_statistics_by_shape_property$exemplarShape == 'arch'], figure_statistics_by_shape_property$totalCount[figure_statistics_by_shape_property$exemplarShape == 'arch'], p=1/3)
binomial_result_arch
binomial_result_lamp <- binom.test(figure_statistics_by_shape_property$shape[figure_statistics_by_shape_property$exemplarShape == 'lamp'], figure_statistics_by_shape_property$totalCount[figure_statistics_by_shape_property$exemplarShape == 'lamp'], p=1/3)
binomial_result_lamp
binomial_result_snowman <- binom.test(figure_statistics_by_shape_property$shape[figure_statistics_by_shape_property$exemplarShape == 'snowman'], figure_statistics_by_shape_property$totalCount[figure_statistics_by_shape_property$exemplarShape == 'snowman'], p=1/3)
binomial_result_snowman
#Store values of 95% confidence intervals.
conf_int_arch <- binomial_result_arch$conf.int
conf_int_lamp <- binomial_result_lamp$conf.int
conf_int_snowman <- binomial_result_snowman$conf.int
#Plot the data for the second figure and save as a file.
ggplot(figure_statistics_by_shape_property_long, aes(x = exemplarShape, y = proportion, fill = exemplarProperty)) +
geom_bar(stat = "identity") + #use the actual proportions
geom_errorbar(aes(ymin = ifelse(exemplarShape == "arch", conf_int_arch[1],
ifelse(exemplarShape == "lamp", conf_int_lamp[1],
conf_int_snowman[1])),
ymax = ifelse(exemplarShape == "arch", conf_int_arch[2],
ifelse(exemplarShape == "lamp", conf_int_lamp[2],
conf_int_snowman[2]))),
width = .2) +
theme_minimal() +
scale_fill_manual(values = c("#B4DCB9", "#7F92B8", "#6C6969")) + #set the bar colors
scale_x_discrete('Extension Shape') + #x-label
scale_y_continuous(labels = scales::percent) + #convert y-axis labels to percent
geom_hline(yintercept = (1/3), linetype = 'dotted', color = 'black') + #add dotted chance line
labs(x = "Shape", y = "Percentage of Responses", fill = "Material") +
labs(fill = "Property Choice") +
theme(legend.title = element_text(size = 12, face = "bold"))
img_path <- file.path(getwd(), '..', 'figures', 'choice_by_shape_and_property_rescue.png')
ggsave(img_path, device = 'png', dpi=300)
#Create a dataframe for the analysis.
rescue_data <- data_main_analyses_tidy |>
select(Age = participantAge,
Experiment = experiment,
Example = exemplarShape,
Choice = participantOverlapProperty,
AgeGroup = ageGroup,
Location = participantLocation)
#Add the offset column.
rescue_data$Offset <- logit(1/3)
#Run the random effects model against chance.
summary(glmer(Choice=="shape" ~ offset(Offset) + 1 + (1 | Example), rescue_data, family="binomial"))
#Create a dataset to merge with the original dataset.
rescue_data <- data_main_analyses_tidy |>
select(Age = participantAge,
Experiment = experiment,
Example = exemplarShape,
Choice = participantOverlapProperty,
AgeGroup = ageGroup,
Location = participantLocation)
#Filter the original dataset for just the Tsimane adult data (Experiment 6, without distractors).
tsimane_adult_data <- original_data |>
filter(Experiment == 'Tsi_Adults_Objects') |>
select(Age, Experiment, Example, Choice, AgeGroup, Location) |>
mutate(Example = tolower(Example), Choice = tolower(Choice)) #Make all values in these columns lowercase.
#Combine the rescue USA adult data and the original data from Experiment 6 (N=39).
appended_data <- rbind(rescue_data, tsimane_adult_data)
#Add the offset column.
appended_data$Offset <- logit(1/3)
#Run the random effects model.
summary(glmer(Choice=="shape" ~ offset(Offset) + Location + (1 + Location | Example), appended_data, family="binomial"))
#Filter the original dataset to remove the USA adult data (and not include two if the Tsimane children experiments).
original_data_no_USA_adult <- original_data |>
filter(Experiment %in% c("Tsi_Adults_Objects","Tsi_Adults_wDistractor", "Tsi_Child_Objects","US_Children")) |>
filter(Choice!="Distractor") |>
select(Age, Experiment, Example, Choice, AgeGroup, Location) |>
mutate(Example = tolower(Example), Choice = tolower(Choice)) #Make all values in these columns lowercase.
#Combine the rescue USA adult data and the original data (minus the US_Turk_Adult subjects).
appended_data_full <- rbind(rescue_data, original_data_no_USA_adult)
#Add the offset column.
appended_data_full$Offset <- logit(1/3)
#Run the logistic mixed-effects model.
summary(glmer(Choice == "shape" ~ offset(Offset) + Location + AgeGroup + (1 + Location + AgeGroup | Example) + (1 | Experiment), appended_data_full, family="binomial"))
suppressMessages(library(knitr))
#Get figure file name.
image_path <- 'choice_by_property_comparison.jpeg'
#Print out the figure.
knitr::include_graphics(image_path)
suppressMessages(library(knitr))
#Get figure file name.
image_path_by_shape <- 'choice_by_shape_and_property_comparison.jpeg'
#Print out the figures.
knitr::include_graphics(image_path_by_shape)
suppressMessages(library(metafor))
#Import meta-analysis data.
meta_analysis_file <- 'meta_analysis_data.csv'
meta_analysis_data <- read.csv(file.path(getwd(), '..', 'data', meta_analysis_file))
#Print out the data.
knitr::kable(meta_analysis_data,
table.attr = "class=\"striped\"",
format = "html")
#Run meta-analysis model for Abdelrahim (2022) and Chen (2023)
meta_analysis_model_random_effects <- rma(yi=random_effects_model_estimate, sei = random_effects_model_SE, slab=Study, data=meta_analysis_data)
summary(meta_analysis_model_random_effects)
#Run meta-analysis model for Jara-Ettinger et al. (2022) and Chen (2023)
meta_analysis_model_logistic_mixed_effects <- rma(yi=logistic_mixed_effects_model_estimate, sei = logistic_mixed_effects_model_SE, slab=Study, data=meta_analysis_data)
summary(meta_analysis_model_logistic_mixed_effects)
#Filter out study without this model.
meta_analysis_data_random_effects <- meta_analysis_data |>
filter(Study != "Jara-Ettinger et al. (2022)")
# Plot mini meta-analysis results.
ggplot(meta_analysis_data_random_effects, aes(x = Study, y = random_effects_model_estimate, size = N)) +
geom_point(data = meta_analysis_data_random_effects) +
coord_flip() +
ylim(-2, 2) +
scale_size_area() +
geom_hline(yintercept = 0, color = "black") +
theme_linedraw() +
theme(legend.position = "none") +
labs(y = "Main effect size on original scale", x = "")
#Filter out study without this model.
meta_analysis_data_logistic_mixed_effects <- meta_analysis_data |>
filter(Study != "Abdelrahim (2022)")
# Plot mini meta-analysis results.
ggplot(meta_analysis_data_logistic_mixed_effects, aes(x = Study, y = logistic_mixed_effects_model_estimate, size = N)) +
geom_point(data = meta_analysis_data_logistic_mixed_effects) +
coord_flip() +
ylim(-2, 2) +
scale_size_area() +
geom_hline(yintercept = 0, color = "black") +
theme_linedraw() +
theme(legend.position = "none") +
labs(y = "Main effect size on original scale", x = "")
forest(meta_analysis_model_random_effects)
forest(meta_analysis_model_logistic_mixed_effects)
funnel(meta_analysis_model_random_effects)
funnel(meta_analysis_model_logistic_mixed_effects)
